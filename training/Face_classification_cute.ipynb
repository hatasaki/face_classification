{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, list_pictures, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMAGE_SIZE = 64 # size\n",
    "IMAGE_CHANNEL = 3 #RGB\n",
    "IMAGE_PIXELS = IMAGE_SIZE*IMAGE_SIZE*IMAGE_CHANNEL\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "target_dir = 'cute/' # 可愛い顔画像\n",
    "other_dir = 'other/' # 上記以外\n",
    "\n",
    "# 顔認識用のカスケード型識別器の読み込み\n",
    "cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def load_face_img(file, target_size):\n",
    "    # 画像ファイル読み込み\n",
    "    img = cv2.imread(file)\n",
    "    \n",
    "    # グレースケール変換\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 顔領域の探索\n",
    "    face = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3, minSize=(60, 60))\n",
    "\n",
    "    # 検出部分の切り出し。最初に検出した１つだけを切り出す（１画像に顔１つが前提）\n",
    "    if len(face):\n",
    "        x, y, w, h = face[0]\n",
    "        face_img = img[y:y+h, x:x+w]\n",
    "    else:\n",
    "        face_img = img\n",
    "    \n",
    "    # サイズの変更\n",
    "    face_img = cv2.resize(face_img, target_size)\n",
    "    \n",
    "    return np.asarray(face_img)\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "    \n",
    "# load images for train\n",
    "# - for target images\n",
    "for picture in list_pictures(target_dir, ext='jpg'):　#拡張子'jpg'ファイルを指定しています\n",
    "    img = img_to_array(load_face_img(picture, target_size=(IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    x.append(img)\n",
    "    y.append(1) # 正解ラベル\n",
    "\n",
    "# - for other images\n",
    "for picture in list_pictures(other_dir, ext='jpg'): #拡張子'jpg'ファイルを指定しています\n",
    "    img = img_to_array(load_face_img(picture, target_size=(IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    x.append(img)\n",
    "    y.append(0) # その他ラベル\n",
    "\n",
    "# arrayに変換\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "\n",
    "# 画素値を0から1の範囲に変換\n",
    "x = x.astype('float32')\n",
    "x = x / 255.0\n",
    "\n",
    "# ラベルをカテゴリに変換\n",
    "y = keras.utils.np_utils.to_categorical(y, NUM_CLASSES)\n",
    "\n",
    "#Kerasのバックエンドで動くTensorFlowとTheanoでは入力チャンネルの順番が違うので場合分けして書いています\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x = x.reshape(x.shape[0], IMAGE_CHANNEL, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    input_shape = (IMAGE_CHANNEL, IMAGE_SIZE, IMAGE_SIZE)\n",
    "else:\n",
    "    x = x.reshape(x.shape[0], IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNEL)\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNEL)\n",
    "\n",
    "# テストデータ作成（評価用なので、今回はテストデータ未作成）\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.0, random_state=211)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #rotation_range=180,\n",
    "    zoom_range=0.3,\n",
    "    #vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.39, # pi/8\n",
    "    channel_shift_range=100,\n",
    "    samplewise_center=True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    data_format=K.image_data_format())\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "learning_rate = 1e-5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "#display model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "model_json = model.to_json()\n",
    "open('model.json', 'w').write(model_json) # モデル\n",
    "model.save_weights('model.h5'); # 重み"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
